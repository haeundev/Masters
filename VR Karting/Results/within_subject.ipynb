{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Set Participant Number HERE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "participant_number = 9580\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:59:23.288308Z",
     "start_time": "2024-07-10T07:59:23.257941Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [
    "def get_sheet(sheet_name, sheet_type):\n",
    "    try:\n",
    "        df = pd.read_excel(f\"{participant_number}.xlsx\", sheet_name=sheet_name, header=None)\n",
    "        if sheet_type == \"mini\":\n",
    "            df.columns = [\"WORD\", \"IS_CORRECT\"]\n",
    "        elif sheet_type == \"training\":\n",
    "            df.columns = [\"WORD\", \"IS_CORRECT\", \"RESPONSE_TIME\"]\n",
    "        elif sheet_type == \"evaluation\":\n",
    "            df.columns = [\"WORD\", \"IS_CORRECT\", \"NOISE_TYPE\"]\n",
    "        print(f\"{sheet_name} sheet processed successfully.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def get_accuracy_average(df):    # cast to bool\n",
    "    if df is None:\n",
    "        return None\n",
    "    else:\n",
    "        percentage = df[\"IS_CORRECT\"].value_counts().get(True, 0) / len(df) * 100\n",
    "        # round to 2 decimal places\n",
    "        return round(percentage, 2)\n",
    "\n",
    "def get_accuracy_of_noise_type(df, noise_type):\n",
    "    if df is None:\n",
    "        return None\n",
    "    else:\n",
    "        noise_df = df[df[\"NOISE_TYPE\"] == noise_type]\n",
    "        return get_accuracy_average(noise_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:59:23.289419Z",
     "start_time": "2024-07-10T07:59:23.264581Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Sheets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE sheet processed successfully.\n"
     ]
    }
   ],
   "source": [
    "sheet_type = 'evaluation'\n",
    "\n",
    "df_pre = get_sheet(\"PRE\", sheet_type)\n",
    "df_mid = get_sheet(\"MID\", sheet_type)\n",
    "df_post = get_sheet(\"POST\", sheet_type)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:59:23.330047Z",
     "start_time": "2024-07-10T07:59:23.268039Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session 1 sheet processed successfully.\n",
      "Session 2 sheet processed successfully.\n",
      "Session 3 sheet processed successfully.\n",
      "Session 4 sheet processed successfully.\n",
      "Session 5 sheet processed successfully.\n"
     ]
    }
   ],
   "source": [
    "sheet_type = 'training'\n",
    "\n",
    "df_session1 = get_sheet(\"Session 1\", sheet_type)\n",
    "df_session2 = get_sheet(\"Session 2\", sheet_type)\n",
    "df_session3 = get_sheet(\"Session 3\", sheet_type)\n",
    "df_session4 = get_sheet(\"Session 4\", sheet_type)\n",
    "df_session5 = get_sheet(\"Session 5\", sheet_type)\n",
    "df_session6 = get_sheet(\"Session 6\", sheet_type)\n",
    "df_session7 = get_sheet(\"Session 7\", sheet_type)\n",
    "df_session8 = get_sheet(\"Session 8\", sheet_type)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:59:23.491066Z",
     "start_time": "2024-07-10T07:59:23.330928Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini 1 sheet processed successfully.\n",
      "Mini 2 sheet processed successfully.\n",
      "Mini 3 sheet processed successfully.\n",
      "Mini 4 sheet processed successfully.\n",
      "Mini 5 sheet processed successfully.\n"
     ]
    }
   ],
   "source": [
    "sheet_type = 'mini'\n",
    "\n",
    "df_mini1 = get_sheet(\"Mini 1\", sheet_type)\n",
    "df_mini2 = get_sheet(\"Mini 2\", sheet_type)\n",
    "df_mini3 = get_sheet(\"Mini 3\", sheet_type)\n",
    "df_mini4 = get_sheet(\"Mini 4\", sheet_type)\n",
    "df_mini5 = get_sheet(\"Mini 5\", sheet_type)\n",
    "df_mini6 = get_sheet(\"Mini 6\", sheet_type)\n",
    "df_mini7 = get_sheet(\"Mini 7\", sheet_type)\n",
    "df_mini8 = get_sheet(\"Mini 8\", sheet_type)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:59:23.642253Z",
     "start_time": "2024-07-10T07:59:23.492812Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare PRE, MID, POST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: {'PRE': np.float64(65.97), 'MID': None, 'POST': None}\n"
     ]
    }
   ],
   "source": [
    "pre_acc = get_accuracy_average(df_pre)\n",
    "mid_acc = get_accuracy_average(df_mid)\n",
    "post_acc = get_accuracy_average(df_post)\n",
    "\n",
    "result = {\n",
    "    \"PRE\": pre_acc,\n",
    "    \"MID\": mid_acc,\n",
    "    \"POST\": post_acc\n",
    "}\n",
    "\n",
    "print(f'Average Accuracy: {result}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:59:23.644562Z",
     "start_time": "2024-07-10T07:59:23.641307Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compare Noise Types within PRE/MID/POST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [],
   "source": [
    "noise_types = [\"Clear\", \"PinkNoise\", \"SingleTalker\"]\n",
    "\n",
    "pre_acc = { noise_type: get_accuracy_of_noise_type(df_pre, noise_type) for noise_type in noise_types }\n",
    "mid_acc = { noise_type: get_accuracy_of_noise_type(df_mid, noise_type) for noise_type in noise_types }\n",
    "post_acc = { noise_type: get_accuracy_of_noise_type(df_post, noise_type) for noise_type in noise_types }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:59:23.647801Z",
     "start_time": "2024-07-10T07:59:23.645675Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE: {'Clear': np.float64(64.58), 'PinkNoise': np.float64(66.67), 'SingleTalker': np.float64(66.67)}\n",
      "MID: {'Clear': None, 'PinkNoise': None, 'SingleTalker': None}\n",
      "POST: {'Clear': None, 'PinkNoise': None, 'SingleTalker': None}\n"
     ]
    }
   ],
   "source": [
    "print(f'PRE: {pre_acc}')\n",
    "print(f'MID: {mid_acc}')\n",
    "print(f'POST: {post_acc}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:59:23.651156Z",
     "start_time": "2024-07-10T07:59:23.648163Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare Sessions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [],
   "source": [
    "def get_valid_sessions():\n",
    "    sessions = [df_session1, df_session2, df_session3, df_session4, df_session5, df_session6, df_session7, df_session8]\n",
    "    return [df for df in sessions if df is not None]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:59:23.653764Z",
     "start_time": "2024-07-10T07:59:23.651817Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Session 1': np.float64(64.29), 'Session 2': np.float64(79.46), 'Session 3': np.float64(77.68), 'Session 4': np.float64(83.93), 'Session 5': np.float64(84.82)}\n"
     ]
    }
   ],
   "source": [
    "sessions = get_valid_sessions()\n",
    "\n",
    "session_accuracies = []\n",
    "for session in sessions:\n",
    "    session_accuracies.append(get_accuracy_average(session))\n",
    "\n",
    "result = { f\"Session {i+1}\": session_accuracies[i] for i in range(len(session_accuracies))}\n",
    "\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:59:23.658453Z",
     "start_time": "2024-07-10T07:59:23.655905Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare Minis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [],
   "source": [
    "def get_valid_minis():\n",
    "    minis = [df_mini1, df_mini2, df_mini3, df_mini4, df_mini5, df_mini6, df_mini7, df_mini8]\n",
    "    return [df for df in minis if df is not None]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:59:23.662151Z",
     "start_time": "2024-07-10T07:59:23.660466Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mini 1': np.float64(100.0), 'Mini 2': np.float64(100.0), 'Mini 3': np.float64(87.5), 'Mini 4': np.float64(100.0), 'Mini 5': np.float64(75.0)}\n"
     ]
    }
   ],
   "source": [
    "minis = get_valid_minis()\n",
    "\n",
    "mini_accuracies = []\n",
    "for mini in minis:\n",
    "    mini_accuracies.append(get_accuracy_average(mini))\n",
    "\n",
    "result = { f\"Mini {i+1}\": mini_accuracies[i] for i in range(len(mini_accuracies))}\n",
    "\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:59:23.695860Z",
     "start_time": "2024-07-10T07:59:23.662609Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Detailed Analysis - Word Level"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate Word Accuracy(0, 0.5, 1) Across Sessions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [],
   "source": [
    "def calculate_accuracy(df):\n",
    "    accuracy_dict = {}\n",
    "    grouped = df.groupby('WORD')\n",
    "    for w, group in grouped:\n",
    "        accuracy = group['IS_CORRECT'].mean()\n",
    "        accuracy_dict[w] = accuracy\n",
    "    acc_df = pd.DataFrame(list(accuracy_dict.items()), columns=['WORD', 'ACCURACY'])\n",
    "    return acc_df\n",
    "\n",
    "\n",
    "def track_accuracies_by_words(dfs, is_eval=False):\n",
    "    acc_df = pd.DataFrame()\n",
    "    if is_eval:\n",
    "        session_names = ['PRE', 'MID']\n",
    "    else:\n",
    "        session_names = [f\"Session {i+1}\" for i in range(len(dfs))]\n",
    "\n",
    "    for df, session_name in zip(dfs, session_names):\n",
    "        # leave only first 2 columns - word, is_correct\n",
    "        session_accuracy = calculate_accuracy(df)\n",
    "        session_accuracy.columns = ['WORD', session_name]\n",
    "        if acc_df.empty:\n",
    "            acc_df = session_accuracy\n",
    "        else:\n",
    "            acc_df = pd.merge(acc_df, session_accuracy, on='WORD', how='outer')\n",
    "\n",
    "    if not acc_df.empty:\n",
    "        acc_df = acc_df.sort_values(by='WORD', key=lambda x: x.str.lower())\n",
    "\n",
    "    return acc_df\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "def save_accuracy_to_excel(df, sheet_name):\n",
    "    excel_file = f\"{participant_number}.xlsx\"\n",
    "\n",
    "    try:\n",
    "        with pd.ExcelWriter(excel_file, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        print(f\"{sheet_name} sheet is saved to {excel_file}\")\n",
    "    except ValueError as e:\n",
    "        if 'Sheet' in str(e) and 'already exists' in str(e):\n",
    "            with pd.ExcelWriter(excel_file, mode='a', engine='openpyxl') as writer:\n",
    "                workbook = load_workbook(excel_file)\n",
    "                if 'Word Accuracies' in workbook.sheetnames:\n",
    "                    del workbook[sheet_name]\n",
    "                    workbook.save(excel_file)\n",
    "                df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:59:23.696166Z",
     "start_time": "2024-07-10T07:59:23.669956Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Accuracies sheet is saved to 9580.xlsx\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'groupby'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[276], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m accuracy_df \u001B[38;5;241m=\u001B[39m track_accuracies_by_words(sessions)\n\u001B[1;32m      2\u001B[0m save_accuracy_to_excel(accuracy_df, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWord Accuracies\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m accuracy_df_eval \u001B[38;5;241m=\u001B[39m \u001B[43mtrack_accuracies_by_words\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdf_pre\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_mid\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m save_accuracy_to_excel(accuracy_df_eval, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEvaluation Word Accuracies\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[275], line 20\u001B[0m, in \u001B[0;36mtrack_accuracies_by_words\u001B[0;34m(dfs, is_eval)\u001B[0m\n\u001B[1;32m     16\u001B[0m     session_names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSession \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(dfs))]\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m df, session_name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(dfs, session_names):\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;66;03m# leave only first 2 columns - word, is_correct\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m     session_accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_accuracy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m     session_accuracy\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWORD\u001B[39m\u001B[38;5;124m'\u001B[39m, session_name]\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m acc_df\u001B[38;5;241m.\u001B[39mempty:\n",
      "Cell \u001B[0;32mIn[275], line 3\u001B[0m, in \u001B[0;36mcalculate_accuracy\u001B[0;34m(df)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcalculate_accuracy\u001B[39m(df):\n\u001B[1;32m      2\u001B[0m     accuracy_dict \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m----> 3\u001B[0m     grouped \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupby\u001B[49m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWORD\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m w, group \u001B[38;5;129;01min\u001B[39;00m grouped:\n\u001B[1;32m      5\u001B[0m         accuracy \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIS_CORRECT\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmean()\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'groupby'"
     ]
    }
   ],
   "source": [
    "accuracy_df = track_accuracies_by_words(sessions)\n",
    "save_accuracy_to_excel(accuracy_df, 'Word Accuracies')\n",
    "\n",
    "accuracy_df_eval = track_accuracies_by_words([df_pre, df_mid], is_eval=True)\n",
    "save_accuracy_to_excel(accuracy_df_eval, 'Evaluation Word Accuracies')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T07:59:23.774638Z",
     "start_time": "2024-07-10T07:59:23.679893Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate Vowel Contrast Accuracy Across Sessions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_contrast(word):\n",
    "    contrast_dict = {\n",
    "        **dict.fromkeys([\"rich\", \"reach\", \"itch\", \"each\", \"sin\", \"scene\", \"list\", \"least\", \"chip\", \"cheap\", \"filled\", \"field\", \"grin\", \"green\"], \"ɪ vs. iː\"),\n",
    "        **dict.fromkeys([\"bet\", \"bat\", \"pet\", \"pat\", \"met\", \"mat\", \"set\", \"sat\", \"ten\", \"tan\", \"men\", \"man\", \"Ken\", \"can\"], \"ɛ vs. æ\"),\n",
    "        **dict.fromkeys([\"cut\", \"cot\", \"but\", \"bot\", \"hut\", \"hot\", \"nut\", \"not\", \"sub\", \"sob\", \"fund\", \"fond\", \"pup\", \"pop\"], \"ʌ vs. ɑ\"),\n",
    "        **dict.fromkeys([\"look\", \"Luke\", \"pull\", \"pool\", \"full\", \"fool\", \"should\", \"shooed\", \"bull\", \"Boole\", \"could\", \"cooed\", \"would\", \"wooed\"], \"ʊ vs. uː\")\n",
    "    }\n",
    "\n",
    "    return contrast_dict.get(word, \"Word not found in the table\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for each word, get the contrast, and across sessions, calculate the accuracy of each contrast. save to excel sheet.\n",
    "def calculate_contrast_accuracy(df):\n",
    "    contrast_dict = {}\n",
    "    grouped = df.groupby('WORD')\n",
    "    for w, group in grouped:\n",
    "        contrast = get_contrast(w)\n",
    "        accuracy = group['IS_CORRECT'].mean()\n",
    "        if contrast in contrast_dict:\n",
    "            contrast_dict[contrast].append(accuracy)\n",
    "        else:\n",
    "            contrast_dict[contrast] = [accuracy]\n",
    "\n",
    "    contrast_accuracy_dict = {}\n",
    "    for contrast, accuracies in contrast_dict.items():\n",
    "        contrast_accuracy_dict[contrast] = sum(accuracies) / len(accuracies)\n",
    "\n",
    "    acc_df = pd.DataFrame(list(contrast_accuracy_dict.items()), columns=['CONTRAST', 'ACCURACY'])\n",
    "    return acc_df\n",
    "\n",
    "\n",
    "def track_contrast_accuracies_by_words(dfs):\n",
    "    acc_df = pd.DataFrame()\n",
    "    session_names = [f\"Session {i+1}\" for i in range(len(dfs))]\n",
    "\n",
    "    for df, session_name in zip(dfs, session_names):\n",
    "        # leave only first 2 columns - word, is_correct\n",
    "        session_accuracy = calculate_contrast_accuracy(df)\n",
    "        session_accuracy.columns = ['CONTRAST', session_name]\n",
    "        if acc_df.empty:\n",
    "            acc_df = session_accuracy\n",
    "        else:\n",
    "            acc_df = pd.merge(acc_df, session_accuracy, on='CONTRAST', how='outer')\n",
    "\n",
    "    if not acc_df.empty:\n",
    "        acc_df = acc_df.sort_values(by='CONTRAST', key=lambda x: x.str.lower())\n",
    "\n",
    "    return acc_df\n",
    "\n",
    "\n",
    "contrast_accuracy_df = track_contrast_accuracies_by_words(sessions)\n",
    "\n",
    "save_accuracy_to_excel(contrast_accuracy_df, 'Contrast Accuracies')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
